<!DOCTYPE html><html lang="zh-cn"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><title>CentOS 7 æ­å»ºSpark2.3.1åˆ†å¸ƒå¼é›†ç¾¤</title>
<link rel="stylesheet" href="/css/layout.css">
<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="/css/vendors/rabbit-lyrics.css">
<link rel="shortcut icon" href="/img/favicon.ico"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="ç®€å•æ˜“æ‡‚ã®ç°ä»£é­”æ³•" type="application/atom+xml">
</head><body><header class="base-menu"><div class="menu-wrapper"><div class="menu-layout-bg"></div><nav class="menu-content"><ul class="menu-list"><li class="menu-item"><a class="menu-link" href="/">ç®€å•æ˜“æ‡‚ã®ç°ä»£é­”æ³•</a></li><li class="menu-item"><a class="menu-link" href="/archives/">Archives</a></li><li class="menu-item"><a class="menu-link" target="_blank" rel="noopener" href="http://weibo.com/u/2360401155">Weibo</a></li><li class="menu-item"><a class="menu-link" href="/about">About</a></li><li class="menu-item"><a class="menu-link" href="/atom.xml">Rss</a></li></ul></nav></div></header><header class="base-mobile-menu"><div class="mobile-menu-wrapper"><div class="menu-layout-bg"></div><nav class="menu-content"><ul class="menu-list"><li class="menu-item"><a class="menu-link" href="/">ç®€å•æ˜“æ‡‚ã®ç°ä»£é­”æ³•</a></li><li class="menu-item"><a class="menu-link" href="/archives/">Archives</a></li><li class="menu-item"><a class="menu-link" target="_blank" rel="noopener" href="http://weibo.com/u/2360401155">Weibo</a></li><li class="menu-item"><a class="menu-link" href="/about">About</a></li><li class="menu-item"><a class="menu-link" href="/atom.xml">Rss</a></li></ul></nav><div class="toggle-menu" id="mobile-menu-toggle"><span class="menu-bar"></span><span class="menu-bar"> </span><span class="menu-bar"></span></div></div></header><div class="base-content"><div class="base-content-main"><article class="article-main"><h1 class="article-title">CentOS 7 æ­å»ºSpark2.3.1åˆ†å¸ƒå¼é›†ç¾¤</h1><div class="article-meta"><p class="meta-item meta-time"><span class="meta-item-title"></span><i class="icon-calendar"> </i>2018-10-26</p><p class="meta-item meta-tag"><span class="meta-item-title"></span><i class="icon-tag"> </i><a class="tag-link" href="/tags/spark/">spark</a></p></div><div class="article-content"><span id="more"></span>
<h2 id="ä¸‹è½½å®‰è£…åŒ…"><a class="header-anchor" href="#ä¸‹è½½å®‰è£…åŒ…">Â¶</a>ä¸‹è½½å®‰è£…åŒ…</h2>
<ol>
<li>å®˜æ–¹ä¸‹è½½</li>
</ol>
<p>ç‚¹å‡»<a target="_blank" rel="noopener" href="http://spark.apache.org/downloads.html">è¿™é‡Œ</a>ä¸‹è½½ï¼Œå®˜æ–¹æä¾›å‡ ç§æ„å»ºæ–¹å¼ã€‚ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œé€‰æ‹©é¢„å…ˆç¼–è¯‘ç‰ˆæœ¬çš„hadoopã€‚</p>
<ol start="2">
<li>å®‰è£…å‰æ</li>
</ol>
<ul>
<li>JDK8</li>
<li>ZooKeeperï¼Œå®‰è£…å‚è€ƒè¿™é‡Œ</li>
<li>Hadoopï¼Œå®‰è£…å‚è€ƒè¿™é‡Œ</li>
<li>Scala</li>
</ul>
<p>æ³¨æ„ï¼šä»Spark2.0ç‰ˆå¼€å§‹ï¼Œé»˜è®¤ä½¿ç”¨Scala 2.11æ„å»ºã€‚Scala 2.10ç”¨æˆ·åº”è¯¥ä¸‹è½½SparkæºåŒ…å¹¶ä½¿ç”¨<a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/building-spark.html#building-for-scala-210">Scala2.10</a>æ”¯æŒæ„å»ºã€‚</p>
<ol start="3">
<li>é›†ç¾¤è§„åˆ’</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:center">èŠ‚ç‚¹åç§°</th>
<th style="text-align:center">IP</th>
<th style="text-align:center">ZooKeeper</th>
<th style="text-align:center">Master</th>
<th style="text-align:center">Worker</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">spark-node1</td>
<td style="text-align:center">192.168.50.200</td>
<td style="text-align:center">ZooKeeper</td>
<td style="text-align:center">ä¸»Master</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">spark-node2</td>
<td style="text-align:center">192.168.50.201</td>
<td style="text-align:center">ZooKeeper</td>
<td style="text-align:center">å¤‡Master</td>
<td style="text-align:center">Worker</td>
</tr>
<tr>
<td style="text-align:center">spark-node3</td>
<td style="text-align:center">192.168.50.202</td>
<td style="text-align:center">ZooKeeper</td>
<td style="text-align:center"></td>
<td style="text-align:center">Worker</td>
</tr>
</tbody>
</table>
<h2 id="é›†ç¾¤å®‰è£…"><a class="header-anchor" href="#é›†ç¾¤å®‰è£…">Â¶</a>é›†ç¾¤å®‰è£…</h2>
<ol>
<li>è§£å‹ç¼©</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 ~]$ tar zxvf spark-2.3.1-bin-hadoop2.7.tgz -C /opt/</span><br><span class="line">[xxx@spark-node1 ~]$ sudo ln -s /opt/spark-2.31-bin-hadoop2.7 /opt/spark</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>ä¿®æ”¹é…ç½®æ–‡ä»¶</li>
</ol>
<ol>
<li>è¿›å…¥é…ç½®æ–‡ä»¶æ‰€åœ¨ç›®å½•</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 ~]$ cd /opt/spark/conf/</span><br><span class="line">[xxx@spark-node1 ~]$ ll</span><br><span class="line">total 36K</span><br><span class="line">-rw-rw-r--. 1 galudisu galudisu  996 Jun  1 16:49 docker.properties.template</span><br><span class="line">-rw-rw-r--. 1 galudisu galudisu 1.1K Jun  1 16:49 fairscheduler.xml.template</span><br><span class="line">-rw-rw-r--. 1 galudisu galudisu 2.0K Jun  1 16:49 log4j.properties.template</span><br><span class="line">-rw-rw-r--. 1 galudisu galudisu 7.7K Jun  1 16:49 metrics.properties.template</span><br><span class="line">-rw-rw-r--. 1 galudisu galudisu  865 Jun  1 16:49 slaves.template</span><br><span class="line">-rw-rw-r--. 1 galudisu galudisu 1.3K Jun  1 16:49 spark-defaults.conf.template</span><br><span class="line">-rwxrwxr-x. 1 galudisu galudisu 4.2K Jun  1 16:49 spark-env.sh.template</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>å¤åˆ¶<code>spark-env.sh.template</code>å¹¶é‡å‘½åä¸º<code>spark-env.sh</code></li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 conf]$ cp spark-env.sh.template spark-env.sh</span><br><span class="line">[xxx@spark-node1 conf]$ vim spark-env.sh</span><br></pre></td></tr></table></figure>
<p>ç¼–è¾‘å¹¶åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ å¦‚ä¸‹é…ç½®å†…å®¹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">æŒ‡å®šé»˜è®¤masterçš„ipæˆ–ä¸»æœºå</span></span><br><span class="line">export SPARK_MASTER_HOST=node21  </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">æŒ‡å®šmaasteræäº¤ä»»åŠ¡çš„é»˜è®¤ç«¯å£ä¸º7077</span>    </span><br><span class="line">export SPARK_MASTER_PORT=7077 </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">æŒ‡å®šmassterèŠ‚ç‚¹çš„webuiç«¯å£</span>       </span><br><span class="line">export SPARK_MASTER_WEBUI_PORT=8080 </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">æ¯ä¸ªworkerä»èŠ‚ç‚¹èƒ½å¤Ÿæ”¯é…çš„å†…å­˜æ•°</span> </span><br><span class="line">export SPARK_WORKER_MEMORY=1g        </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">å…è®¸Sparkåº”ç”¨ç¨‹åºåœ¨è®¡ç®—æœºä¸Šä½¿ç”¨çš„æ ¸å¿ƒæ€»æ•°ï¼ˆé»˜è®¤å€¼ï¼šæ‰€æœ‰å¯ç”¨æ ¸å¿ƒï¼‰</span></span><br><span class="line">export SPARK_WORKER_CORES=1    </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">æ¯ä¸ªworkerä»èŠ‚ç‚¹çš„å®ä¾‹ï¼ˆå¯é€‰é…ç½®ï¼‰</span> </span><br><span class="line">export SPARK_WORKER_INSTANCES=1   </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">æŒ‡å‘åŒ…å«Hadoopé›†ç¾¤çš„ï¼ˆå®¢æˆ·ç«¯ï¼‰é…ç½®æ–‡ä»¶çš„ç›®å½•ï¼Œè¿è¡Œåœ¨Yarnä¸Šé…ç½®æ­¤é¡¹</span>   </span><br><span class="line">export HADOOP_CONF_DIR=/opt/module/hadoop-2.7.6/etc/hadoop</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">æŒ‡å®šæ•´ä¸ªé›†ç¾¤çŠ¶æ€æ˜¯é€šè¿‡zookeeperæ¥ç»´æŠ¤çš„ï¼ŒåŒ…æ‹¬é›†ç¾¤æ¢å¤</span></span><br><span class="line">export SPARK_DAEMON_JAVA_OPTS=&quot;      </span><br><span class="line">-Dspark.deploy.recoveryMode=ZOOKEEPER </span><br><span class="line">-Dspark.deploy.zookeeper.url=node21:2181,node22:2181,node23:2181</span><br><span class="line">-Dspark.deploy.zookeeper.dir=/spark&quot;</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>å¤åˆ¶<code>slaves.template</code>æˆ<code>slaves</code>ï¼Œå¹¶ä¿®æ”¹é…ç½®å†…å®¹</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 conf]$ cp slaves.template slaves</span><br><span class="line">[xxx@spark-node1 conf]$ vim slaves</span><br></pre></td></tr></table></figure>
<p>ä¿®æ”¹ä»èŠ‚ç‚¹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark-node2</span><br><span class="line">spark-node3</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>å°†å®‰è£…åŒ…åˆ†å‘ç»™å…¶å®ƒèŠ‚ç‚¹</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 opt]$ scp -r spark-2.31-bin-hadoop2.7 xxx@spark-node2:/opt/</span><br><span class="line">[xxx@spark-node1 opt]$ scp -r spark-2.31-bin-hadoop2.7 xxx@spark-node3:/opt/</span><br></pre></td></tr></table></figure>
<p>ä¿®æ”¹spark-node2èŠ‚ç‚¹ä¸Š<code>conf/spark-env.sh</code>é…ç½®çš„MasterIPä¸º<code>SPARK_MASTER_IP=spark-node2</code></p>
<ol start="3">
<li>é…ç½®ç¯å¢ƒå˜é‡</li>
</ol>
<p>æ‰€æœ‰èŠ‚ç‚¹å‡è¦é…ç½®</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 spark]$ sudo vim /etc/profile</span><br><span class="line"></span><br><span class="line">export SPARK_HOME=/opt/spark</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin</span><br><span class="line">[xxx@spark-node1 spark]$ source /etc/profile</span><br></pre></td></tr></table></figure>
<h2 id="å¯åŠ¨é›†ç¾¤"><a class="header-anchor" href="#å¯åŠ¨é›†ç¾¤">Â¶</a>å¯åŠ¨é›†ç¾¤</h2>
<ol>
<li>å¯åŠ¨ZooKeeperé›†ç¾¤</li>
</ol>
<p>æ‰€æœ‰ZooKeeperèŠ‚ç‚¹å‡è¦æ‰§è¡Œ</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 ~]$ zkServer.sh start</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>å¯åŠ¨Hadoopé›†ç¾¤</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 ~]$ start-dfs.sh</span><br><span class="line">[xxx@spark-node2 ~]$ start-yarn.sh</span><br><span class="line">[xxx@spark-node3 ~]$ yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>å¯åŠ¨Sparké›†ç¾¤</li>
</ol>
<p>å¯åŠ¨Sparkï¼šå¯åŠ¨masterèŠ‚ç‚¹ï¼š<code>sbin/start-master.sh</code> å¯åŠ¨workerèŠ‚ç‚¹ï¼š<code>sbin/start-slaves.sh</code><br>
æˆ–è€…ï¼š<code>sbin/start-all.sh</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 spark]$ sbin/start-all.sh</span><br></pre></td></tr></table></figure>
<p>æ³¨æ„ï¼šå¤‡ç”¨masterèŠ‚ç‚¹éœ€è¦æ‰‹åŠ¨å¯åŠ¨</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node2 spark]$ sbin/start-master.sh</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>æŸ¥çœ‹è¿›ç¨‹</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 spark]$ jps</span><br><span class="line">2368 JobHistoryServer</span><br><span class="line">2928 Jps</span><br><span class="line">2227 DFSZKFailoverController</span><br><span class="line">2533 Master</span><br><span class="line">2006 JournalNode</span><br><span class="line">1512 NodeManager</span><br><span class="line">1610 NameNode</span><br><span class="line">1820 DataNode</span><br><span class="line"></span><br><span class="line">[xxx@spark-node2 spark]$ jps</span><br><span class="line">2256 DFSZKFailoverController</span><br><span class="line">1651 NameNode</span><br><span class="line">2435 Worker</span><br><span class="line">2101 JournalNode</span><br><span class="line">2854 Jps</span><br><span class="line">1576 NodeManager</span><br><span class="line">1209 ResourceManager</span><br><span class="line">1835 DataNode</span><br><span class="line"></span><br><span class="line">[xxx@spark-node3 spark]$ jps</span><br><span class="line">1796 DataNode</span><br><span class="line">2436 Jps</span><br><span class="line">1900 JournalNode</span><br><span class="line">1613 NodeManager</span><br><span class="line">2095 Worker</span><br></pre></td></tr></table></figure>
<h2 id="éªŒè¯é›†ç¾¤HA"><a class="header-anchor" href="#éªŒè¯é›†ç¾¤HA">Â¶</a>éªŒè¯é›†ç¾¤HA</h2>
<ol>
<li>çœ‹Webé¡µé¢MasterçŠ¶æ€</li>
</ol>
<p>spark-node1æ˜¯ALIVEçŠ¶æ€ï¼Œspark-node2ä¸ºSTANDBYçŠ¶æ€ï¼ŒWebUIæŸ¥çœ‹ï¼š<a target="_blank" rel="noopener" href="http://spark-node1:8080/">http://spark-node1:8080/</a></p>
<p><img src="/img/spark/spark-master1.png" alt="spark-master1"><br>
<img src="/img/spark/spark-master2.png" alt="spark-master2"></p>
<p>ä»èŠ‚ç‚¹è¿æ¥åœ°å€ï¼š<a target="_blank" rel="noopener" href="http://spark-node2:8081">http://spark-node2:8081/</a></p>
<p><img src="/img/spark/spark-worker1.png" alt="spark-worker1"><br>
<img src="/img/spark/spark-worker2.png" alt="spark-worker2"></p>
<ol start="2">
<li>éªŒè¯HAçš„é«˜å¯ç”¨</li>
</ol>
<p>æ‰‹åŠ¨å¹²æ‰spark-node1ä¸Šé¢çš„Masterè¿›ç¨‹ï¼Œspark-node2:8080å°†è‡ªåŠ¨åˆ‡æ¢ä¸ºALIVEçŠ¶æ€ã€‚</p>
<p><img src="/img/spark/spark-alive.png" alt="spark-alive"></p>
<ol start="3">
<li>HAæ³¨æ„ç‚¹</li>
</ol>
<ul>
<li>ä¸»å¤‡åˆ‡æ¢è¿‡ç¨‹ä¸­ä¸èƒ½æäº¤Applicationã€‚</li>
<li>ä¸»å¤‡åˆ‡æ¢è¿‡ç¨‹ä¸­ä¸å½±å“å·²ç»åœ¨é›†ç¾¤ä¸­è¿è¡Œçš„Applicationã€‚å› ä¸ºSparkæ˜¯ç²—ç²’åº¦èµ„æºè°ƒåº¦ã€‚</li>
</ul>
<p><img src="/img/spark/spark-ha.png" alt="spark-ha"></p>
<h2 id="é›†ç¾¤æäº¤å‘½ä»¤æ–¹å¼"><a class="header-anchor" href="#é›†ç¾¤æäº¤å‘½ä»¤æ–¹å¼">Â¶</a>é›†ç¾¤æäº¤å‘½ä»¤æ–¹å¼</h2>
<ol>
<li>Standaloneæ¨¡å¼</li>
</ol>
<h3 id="Standalone-client"><a class="header-anchor" href="#Standalone-client">Â¶</a>Standalone-client</h3>
<ol>
<li>æäº¤å‘½ä»¤</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 spark]$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://spark-node1:7077 \</span><br><span class="line">--executor-memory 500m \</span><br><span class="line">--total-executor-cores 1 \</span><br><span class="line">examples/jars/spark-examples_2.11-2.3.1.jar 10</span><br></pre></td></tr></table></figure>
<p>æˆ–è€…</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node2 spark]$ ./bin/spark-submit --class org.apache.spark.exmaples.SparkPi \</span><br><span class="line">--master spark://spark-node1:7077 \</span><br><span class="line">--deploy-mode client \</span><br><span class="line">--executor-memory 500m \</span><br><span class="line">--total-executor-cores 1 \</span><br><span class="line">examples/jars/spark-examples_2.11-2.3.1.jar 10</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>æäº¤åŸç†å›¾è§£</li>
</ol>
<p><img src="/img/spark/spark-standalone.png" alt="spark-standalone"></p>
<ol start="3">
<li>æ‰§è¡Œæµç¨‹</li>
</ol>
<ul>
<li>clientæ¨¡å¼æäº¤ä»»åŠ¡åï¼Œä¼šåœ¨å®¢æˆ·ç«¯å¯åŠ¨Driverè¿›ç¨‹ã€‚</li>
<li>Driverä¼šå‘Masterç”³è¯·å¯åŠ¨Applicationå¯åŠ¨çš„èµ„æºã€‚</li>
<li>èµ„æºç”³è¯·æˆåŠŸï¼ŒDriverç«¯å°†taskå‘é€åˆ°workerç«¯æ‰§è¡Œã€‚</li>
<li>workerå°†taskæ‰§è¡Œç»“æœè¿”å›åˆ°Driverç«¯ã€‚</li>
</ul>
<ol start="4">
<li>æ€»ç»“</li>
</ol>
<p>clientæ¨¡å¼ä½¿ç”¨äºæµ‹è¯•è°ƒè¯•ç¨‹åºã€‚Driverè¿›ç¨‹æ˜¯åœ¨å®¢æˆ·ç«¯å¯åŠ¨çš„ï¼Œè¿™é‡Œçš„å®¢æˆ·ç«¯å°±æ˜¯æŒ‡æäº¤åº”ç”¨ç¨‹åºçš„å½“å‰èŠ‚ç‚¹ã€‚åœ¨Driverç«¯å¯ä»¥çœ‹åˆ°taskæ‰§è¡Œçš„æƒ…å†µã€‚ç”Ÿäº§ç¯å¢ƒä¸‹ä¸èƒ½ä½¿ç”¨clientæ¨¡å¼ï¼Œæ˜¯å› ä¸ºï¼šå‡è®¾è¦æäº¤100ä¸ªApplicationåˆ°é›†ç¾¤è¿è¡Œï¼ŒDriveræ¯æ¬¡éƒ½ä¼šåœ¨clientç«¯å¯åŠ¨ï¼Œé‚£ä¹ˆå°±ä¼šå¯¼è‡´å®¢æˆ·ç«¯100æ¬¡ç½‘å¡æµé‡æš´å¢çš„é—®é¢˜ã€‚</p>
<h3 id="Standalone-cluster"><a class="header-anchor" href="#Standalone-cluster">Â¶</a>Standalone-cluster</h3>
<ol>
<li>æäº¤å‘½ä»¤</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 spark]$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark:spark-node1:7077 \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">examples/jars/spark-examples_2.11-2.3.1.jar 10</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>æäº¤åŸç†å›¾è§£</li>
</ol>
<p><img src="/img/spark/spark-cluster.png" alt="spark-cluster"></p>
<ol start="3">
<li>æ‰§è¡Œæµç¨‹</li>
</ol>
<ul>
<li>clusteræ¨¡å¼æäº¤åº”ç”¨ç¨‹åºåï¼Œä¼šå‘Masterè¯·æ±‚å¯åŠ¨Driverã€‚</li>
<li>Masteræ¥å—è¯·æ±‚ï¼Œéšæœºåœ¨é›†ç¾¤ä¸€å°èŠ‚ç‚¹å¯åŠ¨Driverè¿›ç¨‹ã€‚</li>
<li>Driverå¯åŠ¨åä¸ºå½“å‰çš„åº”ç”¨ç¨‹åºç”³è¯·èµ„æºã€‚</li>
<li>Driverç«¯å‘é€taskåˆ°workerèŠ‚ç‚¹ä¸Šæ‰§è¡Œã€‚</li>
<li>workerå°†æ‰§è¡Œæƒ…å†µå’Œæ‰§è¡Œç»“æœè¿”å›ç»™Driverç«¯ã€‚</li>
</ul>
<ol start="4">
<li>æ€»ç»“</li>
</ol>
<p>Driverè¿›ç¨‹æ˜¯åœ¨é›†ç¾¤æŸä¸€å°Workerä¸Šå¯åŠ¨çš„ï¼Œåœ¨å®¢æˆ·ç«¯æ— æ³•æŸ¥çœ‹taskçš„æ‰§è¡Œæƒ…å†µçš„ã€‚å‡è®¾è¦æäº¤100ä¸ªapplicationåˆ°é›†ç¾¤è¿è¡Œï¼Œæ¯æ¬¡Driverä¼šéšæœºåœ¨é›†ç¾¤ä¸­æŸä¸€å°Workerä¸Šå¯åŠ¨ï¼Œé‚£ä¹ˆè¿™100æ¬¡ç½‘å¡æµé‡æš´å¢çš„é—®é¢˜å°±æ•£æ­¥åœ¨é›†ç¾¤ä¸Šã€‚</p>
<ol start="2">
<li>Yarnæ¨¡å¼</li>
</ol>
<h3 id="yarn-client"><a class="header-anchor" href="#yarn-client">Â¶</a>yarn-client</h3>
<ol>
<li>æäº¤å‘½ä»¤</li>
</ol>
<p>ä»¥clientæ¨¡å¼å¯åŠ¨Sparkåº”ç”¨ç¨‹åºï¼š</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode client [options] &lt;app jar&gt; [app options]</span><br></pre></td></tr></table></figure>
<p>ä¾‹å¦‚</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 spark]$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode client \</span><br><span class="line">examples/jars/spark-examples_2.11-2.3.1.jar 10</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>æäº¤åŸç†å›¾è§£</li>
</ol>
<p><img src="/img/spark/spark-yarn-standalone.png" alt="spark-yarn"></p>
<ol start="3">
<li>æ‰§è¡Œæµç¨‹</li>
</ol>
<ul>
<li>å®¢æˆ·å•æäº¤ä¸€ä¸ªApplicationï¼Œåœ¨å®¢æˆ·ç«¯å¯åŠ¨ä¸€ä¸ªDriverè¿›ç¨‹ã€‚</li>
<li>åº”ç”¨ç¨‹åºå¯åŠ¨åä¼šå‘RS(ResourceManager)å‘é€è¯·æ±‚ï¼Œå¯åŠ¨AM(ApplicationMaster)çš„èµ„æºã€‚</li>
<li>RSæ”¶åˆ°è¯·æ±‚ï¼Œéšæœºé€‰æ‹©ä¸€å°NM(NodeManager)å¯åŠ¨AMã€‚è¿™é‡Œçš„NMç›¸å½“äºStandaloneä¸­çš„WorkerèŠ‚ç‚¹ã€‚</li>
<li>AMå¯åŠ¨åï¼Œä¼šå‘RSè¯·æ±‚ä¸€æ‰¹containerèµ„æºï¼Œç”¨äºå¯åŠ¨Executorã€‚</li>
<li>RSä¼šæ‰¾åˆ°ä¸€æ‰¹NMè¿”å›ç»™AMï¼Œç”¨äºå¯åŠ¨Executorã€‚</li>
<li>AMä¼šå‘NMå‘é€å‘½ä»¤å¯åŠ¨Executorã€‚</li>
<li>Executorå¯åŠ¨åï¼Œä¼šåå‘æ³¨å†Œç»™Driverï¼ŒDriverå‘é€taskåˆ°Executorï¼Œæ‰§è¡Œæƒ…å†µå’Œç»“æœè¿”å›ç»™Driverç«¯ã€‚</li>
</ul>
<ol start="4">
<li>æ€»ç»“</li>
</ol>
<p>Yarn-clientæ¨¡å¼åŒæ ·æ˜¯é€‚ç”¨äºæµ‹è¯•ï¼Œå› ä¸ºDriverè¿è¡Œåœ¨æœ¬åœ°ï¼ŒDriverä¼šä¸yarné›†ç¾¤ä¸­çš„Executorè¿›è¡Œå¤§é‡çš„é€šä¿¡ï¼Œä¼šé€ æˆå®¢æˆ·æœºç½‘å¡æµé‡çš„å¤§é‡å¢åŠ ã€‚</p>
<p>ApplicationMasterçš„ä½œç”¨ï¼š</p>
<ul>
<li>ä¸ºå½“å‰çš„Applicationç”³è¯·èµ„æº</li>
<li>ç»™NodeManagerå‘é€æ¶ˆæ¯å¯åŠ¨Executor</li>
</ul>
<p>æ³¨æ„ï¼šApplicationMasteræœ‰launchExecutorå’Œç”³è¯·èµ„æºçš„åŠŸèƒ½ï¼Œå¹¶æ²¡æœ‰ä½œä¸šè°ƒåº¦çš„åŠŸèƒ½ã€‚</p>
<h3 id="yarn-cluster"><a class="header-anchor" href="#yarn-cluster">Â¶</a>yarn-cluster</h3>
<ol>
<li>æäº¤å‘½ä»¤</li>
</ol>
<p>ä»¥clusteræ¨¡å¼å¯åŠ¨Sparkåº”ç”¨ç¨‹åºï¼š</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode cluster [options] &lt;app jar&gt; [app options]</span><br></pre></td></tr></table></figure>
<p>ä¾‹å¦‚ï¼š</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[xxx@spark-node1 spark]$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">examples/jars/sprk-examples_2.11-2.3.1.jar 10</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>æäº¤åŸç†å›¾è§£</li>
</ol>
<p><img src="/img/spark/spark-yarn-cluster.png" alt="spark-yarn"></p>
<ol start="3">
<li>æ‰§è¡Œæµç¨‹</li>
</ol>
<ul>
<li>å®¢æˆ·æœºæäº¤Applicationåº”ç”¨ç¨‹åºï¼Œå‘é€è¯·æ±‚åˆ°RS(ResourceManager),è¯·æ±‚å¯åŠ¨AM(ApplicationMaster)</li>
<li>RSæ”¶åˆ°è¯·æ±‚åéšæœºåœ¨ä¸€å°NM(NodeManager)ä¸Šå¯åŠ¨AM(ç›¸å½“äºDriverç«¯)</li>
<li>AMå¯åŠ¨ï¼ŒAMå‘é€è¯·æ±‚åˆ°RSï¼Œè¯·æ±‚ä¸€æ‰¹containerç”¨äºå¯åŠ¨Executor</li>
<li>RSè¿”å›ä¸€æ‰¹NMèŠ‚ç‚¹ç»™AM</li>
<li>AMè¿æ¥åˆ°NM,å‘é€è¯·æ±‚åˆ°NMå¯åŠ¨Executor</li>
<li>Executoråå‘æ³¨å†Œåˆ°AMæ‰€åœ¨çš„èŠ‚ç‚¹çš„Driverï¼ŒDriverå‘é€taskåˆ°Executor</li>
</ul>
<ol start="4">
<li>æ€»ç»“</li>
</ol>
<p>Yarn-Clusterä¸»è¦ç”¨äºç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå› ä¸ºDriverè¿è¡Œåœ¨Yarné›†ç¾¤ä¸­æŸä¸€å°nodeManagerä¸­ï¼Œæ¯æ¬¡æäº¤ä»»åŠ¡çš„Driveræ‰€åœ¨çš„æœºå™¨éƒ½æ˜¯éšæœºçš„ï¼Œä¸ä¼šäº§ç”ŸæŸä¸€å°æœºå™¨ç½‘å¡æµé‡æ¿€å¢çš„ç°è±¡ï¼Œç¼ºç‚¹æ˜¯ä»»åŠ¡æäº¤åä¸èƒ½çœ‹åˆ°æ—¥å¿—ã€‚åªèƒ½é€šè¿‡yarnæŸ¥çœ‹æ—¥å¿—ã€‚</p>
<p>ApplicationMasterçš„ä½œç”¨ï¼š</p>
<ul>
<li>ä¸ºå½“å‰çš„Applicationç”³è¯·èµ„æº</li>
<li>ç»™NodeManagerå‘é€æ¶ˆæ¯å¯åŠ¨Executor</li>
<li>ä»»åŠ¡è°ƒåº¦</li>
</ul>
<p>åœæ­¢é›†ç¾¤ä»»åŠ¡å‘½ä»¤: <code>yarn application -kill applicationID</code></p>
<h2 id="é…ç½®å†å²æœåŠ¡å™¨"><a class="header-anchor" href="#é…ç½®å†å²æœåŠ¡å™¨">Â¶</a>é…ç½®å†å²æœåŠ¡å™¨</h2>
<ol>
<li>ä¸´æ—¶é…ç½®</li>
</ol>
<p>å¯¹æœ¬æ¬¡æäº¤çš„åº”ç”¨ç¨‹åºèµ·ä½œç”¨</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./spark-shell --master spark://node21:7077 </span><br><span class="line">--name myapp1</span><br><span class="line">--conf spark.eventLog.enabled=true</span><br><span class="line">--conf spark.eventLog.dir=hdfs://spark-node1:8020/spark/test</span><br></pre></td></tr></table></figure>
<p>åœæ­¢ç¨‹åºï¼Œåœ¨Web UIä¸­Completed Applicationså¯¹åº”çš„ApplicationIDä¸­èƒ½æŸ¥çœ‹history.</p>
<ol start="2">
<li>æ°¸ä¹…é…ç½®</li>
</ol>
<p><strong>spark-default.confé…ç½®æ–‡ä»¶ä¸­é…ç½®History Serverï¼Œå¯¹æ‰€æœ‰æäº¤çš„Applicationéƒ½èµ·ä½œç”¨</strong></p>
<p>åœ¨å®¢æˆ·ç«¯èŠ‚ç‚¹ï¼Œè¿›å…¥<code>../spark/conf/spark-defaults.conf</code>æœ€ååŠ å…¥</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//å¼€å¯è®°å½•äº‹ä»¶æ—¥å¿—çš„åŠŸèƒ½</span><br><span class="line">spark.eventLog.enabled          true</span><br><span class="line">//è®¾ç½®äº‹ä»¶æ—¥å¿—å­˜å‚¨çš„ç›®å½•</span><br><span class="line">spark.eventLog.dir              hdfs://node21:8020/spark/test</span><br><span class="line">//è®¾ç½®HistoryServeråŠ è½½äº‹ä»¶æ—¥å¿—çš„ä½ç½®</span><br><span class="line">spark.history.fs.logDirectory   hdfs://node21:8020/spark/test</span><br><span class="line">//æ—¥å¿—ä¼˜åŒ–é€‰é¡¹,å‹ç¼©æ—¥å¿—</span><br><span class="line">spark.eventLog.compress         true</span><br></pre></td></tr></table></figure>
<p>å¯åŠ¨HistorySeverï¼š</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./start-history-server.sh</span><br></pre></td></tr></table></figure>
<p>è®¿é—®HistoryServer: spark-node1:18080ï¼Œä¹‹åæ‰€æœ‰æäº¤çš„åº”ç”¨ç¨‹åºè¿è¡ŒçŠ¶å†µéƒ½ä¼šè¢«è®°å½•ã€‚</p>
<h2 id="åŠ å…¥Systemd"><a class="header-anchor" href="#åŠ å…¥Systemd">Â¶</a>åŠ å…¥Systemd</h2>
<p>å’Œå‰é¢ZooKeeperã€HAçš„é…ç½®ä¸€æ ·ï¼Œå°†Sparkçš„å¯åŠ¨åŠ å…¥Systemdï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨ç»´æŠ¤ã€‚åœ¨<code>/usr/lib/systemd/system/spark.serivce</code>åŠ å…¥</p>
<p>å› ä¸ºç”¨äº†ZooKeeperé›†ç¾¤åšç»Ÿä¸€åŒ–ç®¡ç†ï¼Œåªéœ€è¦masterèŠ‚ç‚¹åŠ å…¥serviceå³å¯ã€‚</p>
<p>spark-node1:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Spark, Lightning-fast unified analytics engine</span><br><span class="line">After=network.target remote-fs.target nss-lookup.target network-online.target</span><br><span class="line">Requires=network-online.target</span><br><span class="line">Wants=hadoop.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=galudisu</span><br><span class="line">Group=galudisu</span><br><span class="line">Type=forking</span><br><span class="line">ExecStart=/opt/spark/sbin/start-all.sh &amp;</span><br><span class="line">ExecStop=/opt/spark/sbin/stop-all.sh &amp;</span><br><span class="line">RemainAfterExit=yes</span><br><span class="line">Environment=SPARK_HOME=/opt/spark</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<p>spark-node2:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Spark, Lightning-fast unified analytics engine</span><br><span class="line">After=network.target remote-fs.target nss-lookup.target network-online.target</span><br><span class="line">Requires=network-online.target</span><br><span class="line">Wants=hadoop.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=galudisu</span><br><span class="line">Group=galudisu</span><br><span class="line">Type=forking</span><br><span class="line">ExecStart=/opt/spark/sbin/start-master.sh &amp;</span><br><span class="line">ExecStop=/opt/spark/sbin/stop-master.sh &amp;</span><br><span class="line">RemainAfterExit=yes</span><br><span class="line">Environment=SPARK_HOME=/opt/spark</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<p>åˆæˆ–è€…å•ç‹¬ç¼–å†™ä¸€ä¸ªè„šæœ¬æ‰§è¡Œã€‚</p>
</div></article><nav class="article-nav"><div class="article-nav-prev">ğŸ”™<a href="/2018/10/26/ideal/ideal-reference/">AkkaæŠ€æœ¯æ¶æ„çš„ä¸€äº›æ¶æ„å»ºè®®</a></div><div class="article-nav-next">ğŸ”œ<a href="/2018/10/22/spark/spark-hadoop-1/">Hadoopé›†ç¾¤é…ç½®</a></div></nav><div id="base-discus"><div id="disqus_thread"></div><script>var disqus_shortname = 'barudisshu-github-io';
var disqus_identifier = '2018/10/26/spark/spark-cluster-config/';
var disqus_title = 'CentOS 7 æ­å»ºSpark2.3.1åˆ†å¸ƒå¼é›†ç¾¤';
var disqus_url = 'https://galudisu.info/2018/10/26/spark/spark-cluster-config/';
(function () {
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//#{theme.disqus}.disqus.com/count.js" async>  </script></div></div></div><footer class="base-footer"><div class="footer-wrapper"><span>Â©2016 - 2025 <a href="https://galudisu.info">barudisshu</a>, unless otherwise noted.</span></div></footer><div class="dom-ready">
<script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js"></script>

<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>

<link rel="stylesheet" href="//cdn.bootcss.com/pace/1.0.2/themes/green/pace-theme-flash.min.css">

<script src="/js/base.js"></script>

<script src="/js/rabbit-lyrics.js"></script>
</div></body></html>